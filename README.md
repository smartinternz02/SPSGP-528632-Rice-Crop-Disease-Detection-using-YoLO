# SPSGP-528632-Rice-Crop-Disease-Detection-using-YoLO
Rice Crop Disease Detection using YoLO
Increasing grain production is essential to those areas where food is scarce. Increasing grain production by controlling crop diseases in time should be effective. To construct a prediction model for plant diseases and to build a real-time application for crop diseases in the future, a deep learning-based image detection architecture with a custom backbone was proposed for detecting plant diseases. In order to get a good amount of crop, we need to detect the disease at the earliest. Basically, crop disease diagnosis depends on different characteristics like color, shape, texture, etc. Here the person can capture the images of the crop and then the image will be sent to the trained YOLO model. The model analyzes the image and detects crop diseases like Bacterial Blight, Leaf Smut, White Tip.The ability of YOLO to provide early disease detection, precise pest managementcan greatly enhance crop yield and quality. Its efficiency in detecting multiple disease types simultaneously empowers farmers with comprehensive insights into the health status of their fields. This, in turn, enables informed decision-making, leading to timely interventions that mitigate the spread of diseases and minimize economic losses. Ultimately, the YOLO project's impact extends beyond the agricultural field. Its applications hold the potential to reshape how we approach food security, sustainable practices, and technological advancements in modern agriculture. By leveraging YOLO's capabilities for rice crop disease prediction, we embark on a journey towards healthier crops, increased agricultural productivity, and a more resilient and prosperous farming future.

We have three folders of images in the project Training images dataset with labeling (Microsoft Vott tool is used for labeling) Testing images without labeling After completion(running) of the detector.py file the Test_Image_Detection_Results file(This is the output of the project) gets created

These are the requirements for project **(https://drive.google.com/file/d/12nbA3tZaoK6X4GSYCY1rJb7ri_huG7s7/view?usp=drive_link)** - requirements.txt link

This is the documentation of our project **(https://drive.google.com/file/d/1dNbQWBC7hq00uE1Z6f5szLdU0zP3FTYB/view?usp=sharing)** - documentation link

All the folders of our project are present in this drive link **(https://drive.google.com/drive/folders/1WCR1ruQAUn1u4Os-hJkq1MJ0yT30BlW8?usp=sharing)**

We have three folders of images in the project

Training images dataset with labeling
Testing images without labeling
After completion(running) of the detector.py file  the Test_Image_Detection_Results file(This is the output of the project) gets created

The following are the links for images folders:

This link is for the training images folder **(https://drive.google.com/drive/folders/1OLJ3_zEpxCgWSV80vUalXS6qna4VPTHx?usp=sharing)**

This link is for the testing images folder **(https://drive.google.com/drive/folders/1_IowjWRA7yoAMLqccr1QRU1aUhhfAcgc?usp=drive_link)**

This link is for the Test_Image_Detection_Results folder **(https://drive.google.com/drive/folders/1uE0JWOUX63iPwZXzPk_FHCaVlcpQPeqA?usp=drive_link)**

The whole project was executed using python (version 3.6.7) and anaconda prompt.

Finally the demo link is **(https://drive.google.com/file/d/1e3aidI2E0eK0_Eu_XnRxlp9WJsLfxJsC/view?usp=drivesdk)**
